{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "# from dataset_task2 import Dataset_task2\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_df = pd.read_csv('./data/NIKL_CoLA_train.tsv', sep='\\t')[['sentence', 'acceptability_label']]\n",
    "valid_df = pd.read_csv('./data/NIKL_CoLA_dev.tsv', sep='\\t')[['sentence', 'acceptability_label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>acceptability_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>높은 달이 떴다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>달이 뜸이 높았다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>실없는 사람이 까불까불한다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>나는 철수에게 공을 던졌다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>내가 순이와 둘이서 다툰다.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentence  acceptability_label\n",
       "0        높은 달이 떴다.                    1\n",
       "1       달이 뜸이 높았다.                    0\n",
       "2  실없는 사람이 까불까불한다.                    1\n",
       "3  나는 철수에게 공을 던졌다.                    1\n",
       "4  내가 순이와 둘이서 다툰다.                    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraModel, ElectraTokenizer\n",
    "# Use funnel-kor-base tokenizer\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "class Dataset_task1(Dataset):\n",
    "    def __init__(self, _df, _tokenizer):\n",
    "        sents = list(_df['sentence'])\n",
    "        self.inputs = _tokenizer(sents, padding=\"longest\", return_tensors=\"pt\")\n",
    "        self.labels = torch.tensor(_df['acceptability_label'].values).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "    def get_batch_inputs(self, _inputs, _idx):\n",
    "        _dict = {}\n",
    "        for _key in _inputs.keys():\n",
    "            _dict[_key] = _inputs[_key][_idx]\n",
    "        return _dict\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        _x = self.get_batch_inputs(self.inputs, idx)\n",
    "        _y = self.labels[idx]\n",
    "        return _x, _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset_task1(train_df, tokenizer)\n",
    "valid_dataset = Dataset_task1(valid_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15876, 40])\n",
      "torch.Size([2032, 32])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.inputs['input_ids'].shape)\n",
    "print(valid_dataset.inputs['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kor_model = ElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluation(_dataset, device, model, thres=0., bs=8):\n",
    "    model.eval()\n",
    "    _perm = np.arange(len(_dataset))\n",
    "    y_preds = []; y_true = []\n",
    "    for _idx in range(_perm.shape[0]//bs + 1):\n",
    "        if _idx == _perm.shape[0]//bs:\n",
    "            if _idx*bs < _perm.shape[0]:\n",
    "                indices = _perm[_idx*bs:]\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            indices = _perm[_idx * bs: (_idx+1)*(bs)]\n",
    "        \n",
    "        x, y= _dataset[indices]\n",
    "        for _k in x:\n",
    "            x[_k] = x[_k].to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat = model(x).squeeze()\n",
    "        \n",
    "        preds = (y_hat > thres).float()\n",
    "        y_preds.append(preds.to('cpu').numpy())\n",
    "        y_true.append(y.to('cpu').numpy())\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_preds = np.concatenate(y_preds)    \n",
    "    return matthews_corrcoef(y_true, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class task1_model(nn.Module):\n",
    "    def __init__(self, dropout=0.1, _k=1):\n",
    "        super(task1_model, self).__init__()\n",
    "        self.hid_dim = 768+31 # 768  + 30\n",
    "        self.kor_model = ElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\") \n",
    "        self.mlp = nn.Sequential(                \n",
    "                torch.nn.Dropout(p=dropout),\n",
    "                nn.Linear(self.hid_dim, self.hid_dim),\n",
    "                nn.BatchNorm1d(self.hid_dim),\n",
    "                nn.GELU(),\n",
    "               torch.nn.Dropout(p=dropout),\n",
    "                nn.Linear(self.hid_dim, 1),\n",
    "                )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [inputs1, idx_list1, inputs2, idx_lists2]\n",
    "        # [batch, seq_len, hid_dim] --> [batch, hid_dim] \n",
    "        # [batch, seq, emb]\n",
    "        cls_emb = self.kor_model(**x).last_hidden_state[:, 0, :]\n",
    "#         print(cls_emb.shape)\n",
    "        _mask = (x['input_ids'][0]==0)\n",
    "        seq_emb = self.kor_model(**x).last_hidden_state[:, 1:32, :]\n",
    "#         print(seq_emb.shape)\n",
    "        new_emb = (cls_emb.unsqueeze(1) @ seq_emb.transpose(1,2)).squeeze(1)\n",
    "        out = torch.cat([cls_emb, new_emb], dim=1)\n",
    "        return self.mlp(out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc5bd3c36134aabafec6eb172daece4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1| loss:   0.64 | train mcc: 0.283 | valid mcc: 0.423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "076b19eef27c4348b9d7b9379e80f49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2| loss:   0.55 | train mcc: 0.460 | valid mcc: 0.463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6febc065048c43bc9d7cfbac1f636caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3| loss:   0.50 | train mcc: 0.530 | valid mcc: 0.482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83226c213f9b463c8d0b39ac993a32a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4| loss:   0.47 | train mcc: 0.577 | valid mcc: 0.504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ad2f9c27bd4a5ca3d5e2cd96c4c520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5| loss:   0.44 | train mcc: 0.610 | valid mcc: 0.512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1fb869c64a4543a26779429c447787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6| loss:   0.40 | train mcc: 0.651 | valid mcc: 0.510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c861191c244fd998e17e3ec3d43b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7| loss:   0.38 | train mcc: 0.687 | valid mcc: 0.510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cdecfddbb34f8d8585a7da3e137c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8| loss:   0.35 | train mcc: 0.715 | valid mcc: 0.514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd490664a6144b5fa4fe5371715340ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9| loss:   0.33 | train mcc: 0.734 | valid mcc: 0.514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ef51a25ad04a40969a1b40312dbbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10| loss:   0.30 | train mcc: 0.759 | valid mcc: 0.519\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822572098696460abef549805ca6ae08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11| loss:   0.29 | train mcc: 0.782 | valid mcc: 0.528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14cb69b7351448380ac06f2be0def0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12| loss:   0.26 | train mcc: 0.805 | valid mcc: 0.524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655de1913dff41c88562e9fd65ba7661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13| loss:   0.24 | train mcc: 0.822 | valid mcc: 0.517\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e000c88d9243d8aa705718c37ada7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14| loss:   0.23 | train mcc: 0.843 | valid mcc: 0.512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de389da5d45b4c7db370cae087916631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7146/216638472.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Gradient clipping?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: implement codes for saving the best model\n",
    "device = torch.device(\"cuda:2\") #  if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "DROPOUT = 0.2 # 0.1 # 0.1/ 3 layer/ w/o batchnorm에서 88.4\n",
    "EPOCHS = 15\n",
    "bs = 32\n",
    "# MAX_NORM = 1. # \n",
    "\n",
    "model = task1_model(dropout=DROPOUT, _k=1).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=15e-7) # 1e-6 --> 54.3\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    progress_bar = tqdm(range(len(train_dataset)//bs+1))\n",
    "    # generate random permutation for a batch\n",
    "    _perm = np.random.permutation(len(train_dataset))\n",
    "    y_preds = []; y_true = []\n",
    "    loss_sum = 0.\n",
    "    for _idx in range(_perm.shape[0]//bs+1):\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get batch items            \n",
    "        if _idx == _perm.shape[0]//bs:\n",
    "            if _idx*bs < _perm.shape[0]:\n",
    "                indices = _perm[_idx*bs:]\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            indices = _perm[_idx * bs: (_idx+1)*(bs)]\n",
    "            \n",
    "            \n",
    "        x, y= train_dataset[indices]\n",
    "        for _k in x:\n",
    "            x[_k] = x[_k].to(device)  \n",
    "        y = y.to(device).squeeze()\n",
    "        \n",
    "        y_hat = model(x).squeeze()\n",
    "        preds = (y_hat > 0.).float()\n",
    "    \n",
    "        loss = bce_loss(y_hat, y)\n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        # Gradient clipping?\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_NORM)\n",
    "        progress_bar.update(1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_preds.append(preds.to('cpu').numpy())\n",
    "        y_true.append(y.to('cpu').numpy())    \n",
    "        \n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_preds = np.concatenate(y_preds)        \n",
    "    # train_acc = evaluation(train_dataset, model, bs=8)\n",
    "    loss_sum /= (len(train_dataset)//bs+1)\n",
    "    train_mcc = matthews_corrcoef(y_true, y_preds)\n",
    "    valid_mcc = evaluation(valid_dataset, device, model, bs=64)\n",
    "    print(f\"Epoch {epoch}| loss: {loss_sum:6.2f} | train mcc: {train_mcc:.3f} | valid mcc: {valid_mcc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_17",
   "language": "python",
   "name": "nlp_17"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
